<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title>昶月</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="昶月">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="昶月">
<meta property="og:locale" content="zh-cn">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="昶月">
  
    <link rel="alternate" href="/atom.xml" title="昶月" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">昶月</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-Docker-Front-End-Sep-04" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/02/27/Docker-Front-End-Sep-04/" class="article-date">
  <time datetime="2019-02-27T07:34:08.000Z" itemprop="datePublished">2019-02-27</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/02/27/Docker-Front-End-Sep-04/">Docker环境下的前后端分离项目部署与运维04:后端项目部署</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>内容来源：<a href="https://coding.imooc.com/class/219.html" target="_blank" rel="noopener">Docker环境下的前后端分离项目部署与运维</a></p>
<p>在前两节我们分别完成了pxc集群和redis集群的搭建。在这一节中我们将尝试部署<a href="https://www.renren.io/guide" target="_blank" rel="noopener">renren-fast</a>开源项目的后端部分。</p>
<p>首先我们梳理一下前面部署的容器和服务所使用的IP和端口。</p>
<table>
<thead>
<tr>
<th style="text-align:left">左对齐标题</th>
<th style="text-align:right">右对齐标题</th>
<th style="text-align:center">居中对齐标题</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">短文本</td>
<td style="text-align:right">中等文本</td>
<td style="text-align:center">稍微长一点的文本</td>
</tr>
<tr>
<td style="text-align:left">稍微长一点的文本</td>
<td style="text-align:right">短文本</td>
<td style="text-align:center">中等文本</td>
</tr>
</tbody>
</table>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/02/27/Docker-Front-End-Sep-04/" data-id="cjsu8vdc50008jwcztw7iywzy" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/docker/">docker</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/renren-fast/">renren-fast</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-footballStarBase-01" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/01/30/footballStarBase-01/" class="article-date">
  <time datetime="2019-01-30T02:09:57.000Z" itemprop="datePublished">2019-01-30</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/01/30/footballStarBase-01/">iris+xorm Go语言开发球星库(一)</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>内容来源：<a href="https://www.imooc.com/learn/1066" target="_blank" rel="noopener">iris+xorm Go语言开发球星库</a></p>
<p>课程代码：<a href="https://github.com/yz124/superstar" target="_blank" rel="noopener">https://github.com/yz124/superstar</a></p>
<p>首先看我们要实现的球星库具有哪些功能。</p>
<p>球星列表（首页、搜索结果）<br>球星详情（个人资料展示）<br>管理后台（数据列表，信息增删改查）</p>
<p>关键技术点<br>开发语言:golang<br>web框架：iris<br>xorm,template,bootstrap</p>
<div align="center"><br><img src="https://i.imgur.com/knBiBme.png" width="458" height="230"><br></div>

<h2 id="iris常用功能"><a href="#iris常用功能" class="headerlink" title="iris常用功能"></a>iris常用功能</h2><p>实例文档：<a href="https://github.com/iris-contrib/examples#table-of-contents" target="_blank" rel="noopener">https://github.com/iris-contrib/examples#table-of-contents</a></p>
<p>路由规则设置</p>
<pre><code># Get,Post方法
app.Handle(&quot;GET&quot;, &quot;/&quot;, func(ctx iris.Context){...})
app.Get(&quot;/home&quot;, func(ctx iris.Context){...})
app.Get(&quot;/donate&quot;, donateHandler, donateFinishHandler)

# 格式化参数和子目录
# userid 是一个int型参数，最小值是1
app.Get(&quot;/user/{userid:int min(1)}&quot;, func(ctx iris.Context){...})
# adminRouters.Get就处理路径为&quot;/admin/login&quot;的请求
adminRouters := app.Party(&quot;/admin&quot;, adminMiddleware)
adminRouters.Get(&quot;/login&quot;, func(ctx iris.Context){...})

# 子域名
v1 := app.Party(&quot;v1.&quot;)
usersAPI := v1.Party(&quot;/api/users&quot;)
usersAPI.Get(&quot;/{userid:int}&quot;, func(ctx iris.Context){...})
</code></pre><p>一个简单的helloworld</p>
<p>main.go</p>
<pre><code>import (
    &quot;github.com/kataras/iris&quot;
)

func main() {
    app := iris.New()

    htmlEngine := iris.HTML(&quot;/superstar/_demo/iris&quot;, &quot;.html&quot;)
    app.RegisterView(htmlEngine)

    app.Get(&quot;/&quot;, func(ctx iris.Context) {
        ctx.WriteString(&quot;Hello world! -- from iris.&quot;)
    })

    # 使用模板加载页面
    app.Get(&quot;/hello&quot;, func(ctx iris.Context) {
        ctx.ViewData(&quot;Title&quot;, &quot;测试页面&quot;)
        ctx.ViewData(&quot;Content&quot;, &quot;Hello world! -- from template&quot;)
        ctx.View(&quot;hello.html&quot;)
    })

    app.Run(iris.Addr(&quot;:8080&quot;), iris.WithCharset(&quot;UTF-8&quot;))
}
</code></pre><p>hello.html</p>
<pre><code>&lt;!DOCTYPE html&gt;
&lt;html lang=&quot;en&quot;&gt;
&lt;head&gt;
    &lt;meta charset=&quot;UTF-8&quot;&gt;
    &lt;title&gt;{{.Title}}&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
{{.Content}}
&lt;/body&gt;
&lt;/html&gt;
</code></pre><h2 id="xorm"><a href="#xorm" class="headerlink" title="xorm"></a>xorm</h2><p>项目地址：<a href="https://github.com/go-xorm/xorm" target="_blank" rel="noopener">https://github.com/go-xorm/xorm</a><br>支持原生SQL，也有orm结构化支持</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/01/30/footballStarBase-01/" data-id="cjsu8vdcd000fjwczrtrj5xfo" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/golang/">golang</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/iris/">iris</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/xorm/">xorm</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Docker-Front-End-Sep-03" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/01/29/Docker-Front-End-Sep-03/" class="article-date">
  <time datetime="2019-01-29T04:29:02.000Z" itemprop="datePublished">2019-01-29</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/01/29/Docker-Front-End-Sep-03/">Redis集群搭建</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>内容来源：<a href="https://coding.imooc.com/class/219.html" target="_blank" rel="noopener">Docker环境下的前后端分离项目部署与运维</a></p>
<p>这次内容时使用docker搭建Redis集群。</p>
<p>首先说高速缓存的特点。</p>
<ul>
<li>高速缓存利用内存存储数据，读写速度远超硬盘。</li>
<li>高速缓存可以减少I/O操作，降低I/O压力。</li>
</ul>
<p>Redis介绍</p>
<ul>
<li>Redis是VMware开发的开源免费的KV型NoSQL缓存产品</li>
<li>良好的性能，最多可提供10万次/秒的读写</li>
<li>目前新浪微博团队组建了世界上最大规模的Redis集群</li>
</ul>
<p>Redis集群介绍</p>
<ul>
<li>RedisCluster: 官方推荐，只有主从节点，没有中心节点（采用）</li>
<li>Codis： 360公司推出的，中间件产品，存在中心节点。一旦中心结点宕机，集群不能工作</li>
<li>Twemproxy: 中间件产品，存在中心节点（较老）</li>
</ul>
<p>RedisCluster介绍</p>
<ul>
<li>无中心节点，每个节点都是可读可写，客户端与redis节点直连，不需要中间代理层</li>
<li>数据可以被分片存储，每个节点存储的数据不同（与PXC集群不同）；如果一个节点挂掉了，需要有冗余节点继续提供服务（备份）。</li>
<li>管理方便，后续可自行增加和摘除节点<div align="center"><br><img src="https://i.imgur.com/YRulv43.png" width="490" height="330"><br></div>

</li>
</ul>
<p>RedisCluster主从同步</p>
<p>由于集群中每个节点存储的数据都不一样，一旦节点宕机数据无法恢复。所以每个节点都要有备用节点。这里称前者为主节点，后者为从节点。</p>
<ul>
<li>Redis集群中的数据库复制是通过主从同步来实现</li>
<li>集群中主节点（Master）把数据分发给从节点（slave）</li>
<li>主从同步的优点：高可用，Reids节点有冗余设计</li>
</ul>
<p>RedisCluster高可用</p>
<ul>
<li>Redis集群应该包含奇数个Master，至少有3个Master（原因：Redis集群和PXC节点有选举功能。当集群中挂掉的节点数目超过集群节点数目的一半时，剩余节点是无法组成新的集群的。当一个节点挂掉，剩下的节点如果超过总数的一半，则通过选举选出中心节点，组成新的集群。只有2个节点则不可用）</li>
<li>Redis集群中每个Master都应该有Slave。在写入数据的时候，向任何一个master节点写入数据都可以，这些master节点可以自行进行数据的分割存储。即我们可以通过Redis客户端向任意一个master节点读写数据，不管数据是否应该存储在这个节点上。<div align="center"><br><img src="https://i.imgur.com/Bv6mVXG.png" width="415" height="145"><br></div>

</li>
</ul>
<h2 id="运行Redis节点"><a href="#运行Redis节点" class="headerlink" title="运行Redis节点"></a>运行Redis节点</h2><p>下载需要的镜像&amp;创建Redis网络</p>
<pre><code># 下载redis镜像
docker pull yyyyttttwwww/redis
# 给镜像改名
docker tag yyyyttttwwww/redis:latest redis
docker rmi yyyyttttwwww/redis:latest
# 创建Redis网络
docker network create --subnet=172.20.0.0/16 net2
</code></pre><p>启动&amp;配置结点</p>
<pre><code># 启动节点
docker run -it -d --name r1 -p 6001:6379 --net=net2 --ip=172.20.0.2 redis bash
# 进入redis节点内修改配置文件
docker exec -it r1 bash
vi /usr/redis/redis.conf
</code></pre><p>redis.conf配置文件修改下列选项（建议使用vi的搜索功能来查找）</p>
<pre><code>daemonize yes                       #以后台进程运行
cluster-enabled yes                 #开启集群
cluster-config-file nodes.conf      #集群配置文件
cluster-node-timeout 15000          #超时时间
appendonly yes                      #开启AOF模式（日志功能）
</code></pre><p>根据<a href="http://ztxpp.cc/2019/01/20/dockerStudy3/#5-1-Redis%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E9%9B%86%E7%BE%A4%E4%BB%8B%E7%BB%8D" target="_blank" rel="noopener">前人经验</a>，配置文件还需要修改一个东西：</p>
<pre><code>bind 127.0.0.1
# 修改为
bind 172.20.0.2(总之就是修改成这个容器分配的IP)
</code></pre><p>注意要删掉127.0.0.1，此处是redis的一个bug, 参照<a href="https://stackoverflow.com/a/53128159" target="_blank" rel="noopener">stack overflow</a>的解答方案。</p>
<pre><code># 在容器中启动Redis
cd /usr/redis/src/
./redis-server ../redis.conf
# 退出r1
exit
</code></pre><p>至此第一个redis结点已经成功启动，按照相同方法启动剩余5个节点。</p>
<h2 id="安装-redis-trib-rb"><a href="#安装-redis-trib-rb" class="headerlink" title="安装 redis-trib.rb"></a>安装 redis-trib.rb</h2><p>redis自带了创建redis集群的工具：redis-trib。借助redis-trib可以创建redis集群，但是redis-trib操作很麻烦，所以这里使用写好的脚本redis-trib.rb来完成一系列工作（镜像中已存在），这是一个ruby的脚本。<br>根据redis-trib.rb脚本（基于Ruby的redis集群命令行工具）安装</p>
<pre><code># 进入任一redis容器
docker exec -it r1 bash
# 进入/redis目录
cd /usr/redis
# 创建cluster集群配置文件所在目录
mkdir cluster
# 复制集群配置文件
cp /usr/redis/src/redis-trib.rb /usr/redis/cluster
cd /usr/redis/cluster
# 在上面下载的redis镜像中，其实已经安装好了ruby环境，所以如果是按照上面的流程走过来的下面三个步骤就可以跳过了
apt-get install ruby
apt-get install rubygems
gem install redis
</code></pre><p>创建集群（–replicas 1表示1个master节点对应1个slave节点）</p>
<pre><code>./redis-trib.rb create --replicas 1 172.20.0.2:6379 172.20.0.3:6379 172.20.0.4:6379 172.20.0.5:6379 172.20.0.6:6379 172.20.0.7:6379
</code></pre><p>创建成功可以看到下面输出</p>
<pre><code>Using 3 masters:
172.20.0.2:6379
172.20.0.3:6379
172.20.0.4:6379
Adding replica 172.20.0.5:6379 to 172.20.0.2:6379
Adding replica 172.20.0.6:6379 to 172.20.0.3:6379
Adding replica 172.20.0.7:6379 to 172.20.0.4:6379
M: 419e57dd5b6c00808ae06c55e147baa77999b0b0 172.20.0.2:6379
   slots:0-5460 (5461 slots) master
M: a9ac037b1f778bae462b7656454e4915fb554b2b 172.20.0.3:6379
   slots:5461-10922 (5462 slots) master
M: f81def999c98e80b5e8f8b64374959db30e0e2a1 172.20.0.4:6379
   slots:10923-16383 (5461 slots) master
S: 6c5aed9c77f3b25a00b6d62985894294bd189300 172.20.0.5:6379
   replicates 419e57dd5b6c00808ae06c55e147baa77999b0b0
S: 62ae38a5e32d493bb928a9d006248a53657db8d6 172.20.0.6:6379
   replicates a9ac037b1f778bae462b7656454e4915fb554b2b
S: 14b379e099eef3683e082836ef78e56d585d8294 172.20.0.7:6379
   replicates f81def999c98e80b5e8f8b64374959db30e0e2a1
Can I set the above configuration? (type &apos;yes&apos; to accept): yes
&gt;&gt;&gt; Nodes configuration updated
&gt;&gt;&gt; Assign a different config epoch to each node
&gt;&gt;&gt; Sending CLUSTER MEET messages to join the cluster
Waiting for the cluster to join...
&gt;&gt;&gt; Performing Cluster Check (using node 172.20.0.2:6379)
M: 419e57dd5b6c00808ae06c55e147baa77999b0b0 172.20.0.2:6379
   slots:0-5460 (5461 slots) master
M: a9ac037b1f778bae462b7656454e4915fb554b2b 172.20.0.3:6379
   slots:5461-10922 (5462 slots) master
M: f81def999c98e80b5e8f8b64374959db30e0e2a1 172.20.0.4:6379
   slots:10923-16383 (5461 slots) master
M: 6c5aed9c77f3b25a00b6d62985894294bd189300 172.20.0.5:6379
   slots: (0 slots) master
   replicates 419e57dd5b6c00808ae06c55e147baa77999b0b0
M: 62ae38a5e32d493bb928a9d006248a53657db8d6 172.20.0.6:6379
   slots: (0 slots) master
   replicates a9ac037b1f778bae462b7656454e4915fb554b2b
M: 14b379e099eef3683e082836ef78e56d585d8294 172.20.0.7:6379
   slots: (0 slots) master
   replicates f81def999c98e80b5e8f8b64374959db30e0e2a1
[OK] All nodes agree about slots configuration.
&gt;&gt;&gt; Check for open slots...
&gt;&gt;&gt; Check slots coverage...
[OK] All 16384 slots covered.
</code></pre><h2 id="测试RedisCluster集群"><a href="#测试RedisCluster集群" class="headerlink" title="测试RedisCluster集群"></a>测试RedisCluster集群</h2><pre><code># 在r1中调用redis客户端
cd /usr/redis/src/
./redis-cli -c -h 172.20.0.2
# 存储一个值
172.20.0.2:6379&gt; set a 10
-&gt; Redirected to slot [15495] located at 172.20.0.4:6379
OK
172.20.0.2:6379&gt; 
# 可以看到a的值存在了r3上，现在我们将r3宕机，看r7是否可以发挥作用
# 在宿主机内
docker pause r3
# 使用r1连接客户端，查看集群
./redis-cli -c -h 172.20.0.2
172.20.0.7:6379&gt; cluster nodes
14b379e099eef3683e082836ef78e56d585d8294 172.20.0.7:6379 myself,master - 0 0 7 connected 10923-16383
62ae38a5e32d493bb928a9d006248a53657db8d6 172.20.0.6:6379 slave a9ac037b1f778bae462b7656454e4915fb554b2b 0 1548733821169 2 connected
f81def999c98e80b5e8f8b64374959db30e0e2a1 172.20.0.4:6379 master,fail - 1548733476548 1548733472540 3 connected
419e57dd5b6c00808ae06c55e147baa77999b0b0 172.20.0.2:6379 master - 0 1548733819166 1 connected 0-5460
6c5aed9c77f3b25a00b6d62985894294bd189300 172.20.0.5:6379 slave 419e57dd5b6c00808ae06c55e147baa77999b0b0 0 1548733821669 4 connected
a9ac037b1f778bae462b7656454e4915fb554b2b 172.20.0.3:6379 master - 0 1548733815157 2 connected 5461-10922
# r3已经是fail了
# 再看a的值，已经存在r6上了
172.20.0.2:6379&gt; get a
-&gt; Redirected to slot [15495] located at 172.20.0.7:6379
&quot;10&quot;
</code></pre><p>下面恢复r3节点，查看cluster状态，发现r3节点重新上线，但是成为了slave节点。</p>
<pre><code># 在宿主机内
docker unpause r3
# 使用r1连接客户端，查看集群
./redis-cli -c -h 172.20.0.2
172.20.0.7:6379&gt; cluster nodes
62ae38a5e32d493bb928a9d006248a53657db8d6 172.20.0.6:6379 slave a9ac037b1f778bae462b7656454e4915fb554b2b 0 1548733977152 5 connected
14b379e099eef3683e082836ef78e56d585d8294 172.20.0.7:6379 master - 0 1548733975147 7 connected 10923-16383
f81def999c98e80b5e8f8b64374959db30e0e2a1 172.20.0.4:6379 slave 14b379e099eef3683e082836ef78e56d585d8294 0 1548733979155 7 connected
6c5aed9c77f3b25a00b6d62985894294bd189300 172.20.0.5:6379 slave 419e57dd5b6c00808ae06c55e147baa77999b0b0 0 1548733980156 4 connected
419e57dd5b6c00808ae06c55e147baa77999b0b0 172.20.0.2:6379 myself,master - 0 0 1 connected 0-5460
a9ac037b1f778bae462b7656454e4915fb554b2b 172.20.0.3:6379 master - 0 1548733976149 2 connected 5461-10922
</code></pre><p>至此，Redis集群就已经搭建完毕了</p>
<div align="center"><br><img src="https://i.imgur.com/gxucByd.png"><br></div>

<p>参考链接：<br><a href="http://ztxpp.cc/2019/01/20/dockerStudy3/#5-1-Redis%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E9%9B%86%E7%BE%A4%E4%BB%8B%E7%BB%8D" target="_blank" rel="noopener">http://ztxpp.cc/2019/01/20/dockerStudy3/#5-1-Redis%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E9%9B%86%E7%BE%A4%E4%BB%8B%E7%BB%8D</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/01/29/Docker-Front-End-Sep-03/" data-id="cjsu8vdc9000bjwcz8zmp7611" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/docker/">docker</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/redis/">redis</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-firewall-centos7" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/01/16/firewall-centos7/" class="article-date">
  <time datetime="2019-01-16T01:05:51.000Z" itemprop="datePublished">2019-01-16</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/01/16/firewall-centos7/">Centos7上防火墙常用设置</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>查看、启动、关闭、重启防火墙</p>
<pre><code>firewall-cmd --state
service firewall start
service firewall stop
service firewall restart
</code></pre><p>查看开启端口和服务</p>
<pre><code># 查看哪些端口已经开启
firewall-cmd --permanent --list-ports
# 查看有哪些使用互联网的服务
firewall-cmd --permanent --list-services
</code></pre><p>开启端口</p>
<pre><code># 开启8080-8085的端口，如果只需要开启一个就只写那一个端口就行
firewall-cmd --permanent --add-port=8080-8085/tcp
# 需要重新加载一下设置
firewall-cmd --reload
</code></pre><p>关闭端口</p>
<pre><code># 端口怎么开启的就怎么关闭。像上面一次开启了5个端口，就不能只关闭其中一个
firewall-cmd --permanent --remove-port=8080-8085/tcp
# 重新加载配置
firewall-cmd --reload
</code></pre><p><img src="https://i.imgur.com/KAGEQGM.png" alt=""></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/01/16/firewall-centos7/" data-id="cjsu8vdca000cjwczvvu0y2x6" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/centos7/">centos7</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/firewall/">firewall</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Docker-Front-End-Sep-02" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/01/15/Docker-Front-End-Sep-02/" class="article-date">
  <time datetime="2019-01-15T07:00:29.000Z" itemprop="datePublished">2019-01-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/01/15/Docker-Front-End-Sep-02/">Docker环境下的前后端分离项目部署与运维02:高可用MySQL集群搭建</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>内容来源：<a href="https://coding.imooc.com/class/219.html" target="_blank" rel="noopener">Docker环境下的前后端分离项目部署与运维</a></p>
<p>这篇文档主要包含三个部分：</p>
<ul>
<li>使用docker搭建MySQL集群</li>
<li>使用haproxy做负载均衡并实现双机热备</li>
<li>利用XtraBackup完成数据库的热备份和冷还原</li>
</ul>
<h2 id="1-使用docker搭建MySQL集群"><a href="#1-使用docker搭建MySQL集群" class="headerlink" title="1. 使用docker搭建MySQL集群"></a>1. 使用docker搭建MySQL集群</h2><p>这一部分学习使用docker搭建MySQL集群。常用的MySQL集群方案有Replication和PXC两种，性能对比如图。</p>
<div align="center"><br><img src="https://i.imgur.com/3AwafEQ.png" width="700" height="330"><br></div>

<p>Percona XtraDB Cluster（简称PXC集群）提供了MySQL高可用的一种实现方法。PXC方案数据同步是双向的，在每一个节点写入数据都会同步到其他节点上。</p>
<div align="center"><br><img src="https://i.imgur.com/8GsSMHM.png" width="440" height="270"><br></div>

<p>Replication方案数据同步是单向的，slave节点只能同步master节点的信息，在salve节点上写入的信息不会被同步到集群中其他节点。</p>
<div align="center"><br><img src="https://i.imgur.com/fKnfEHL.png" width="330" height="229"><br></div>

<p>PXC的数据强一致性表现在同步复制，事务在所有集群节点要么同时提交，要么不提交。事务到达某一数据库节点后，通过同步机制，这条事务被扩散到集群所有节点上，只有所有节点都成功写入，才返回给客户端写入成功信息，否则所有节点都撤销此次写入。而Replication采用异步复制，无法保证数据一致性。事务到达master节点，master节点写入成功后即返回给客户端写入成功信息，随后slave节点开始同步master节点信息，如果在这个环节同步失败则会出现数据库不一致性。</p>
<div align="center"><br><img src="https://i.imgur.com/bFP1lwB.png" width="420" height="230"><br><img src="https://i.imgur.com/XTszPBS.png" width="372" height="149"><br></div>

<h3 id="1-1-获取镜像-amp-建立集群网络"><a href="#1-1-获取镜像-amp-建立集群网络" class="headerlink" title="1.1 获取镜像&amp;建立集群网络"></a>1.1 获取镜像&amp;建立集群网络</h3><p>我们用PXC方案来建立MySQL集群。PXC集群建议使用PerconaServer（MySQL改进版，性能提升大）作为数据库节点。</p>
<p>具体而言，使用PXC官方docker镜像来完成安装。</p>
<pre><code># 下载镜像
docker pull percona/percona-xtradb-cluster
# pxc镜像名字太长了，给它改个名，就叫pxc
docker tag percona/percona-xtradb-cluster pxc
# 原先的tag就可以删除掉了
docker rmi percona/percona-xtradb-cluster
# 给PXC创建docker网段，名字叫net1
docker network create --subnet=172.19.0.0/16 net1
</code></pre><ul>
<li><p>如果在创建网络时docker报错：“ERROR: Failed to Setup IP tables: Unable to enable SKIP DNAT rule:  (iptables failed: iptables –wait -t nat -I DOCKER -i br-2add1a39bc5d -j RETURN: iptables: No chain/target/match by that name.”原因是关闭防火墙之后docker需要重启。执行以下命令重启docker即可</p>
<p>  service docker restart</p>
</li>
</ul>
<ul>
<li>如果报错“Error response from daemon: Pool overlaps with other one on this address space”，说明这一网段已经被占用，换一个网段例如172.20.0.0/16即可</li>
</ul>
<h3 id="1-2-创建数据卷"><a href="#1-2-创建数据卷" class="headerlink" title="1.2 创建数据卷"></a>1.2 创建数据卷</h3><p>PXC技术有个问题，就是不能做volume映射，不能说把宿主机的某个目录和容器的目录映射起来。那么为了在PXC中保存数据，就采用创建volume的方法</p>
<pre><code># 我们计划创建包含5个节点的PXC集群，在这里创建5个volume
docker volume create --name v1
docker volume create --name v2
docker volume create --name v3
docker volume create --name v4
docker volume create --name v5
</code></pre><h3 id="1-3-创建第一个数据库节点node1"><a href="#1-3-创建第一个数据库节点node1" class="headerlink" title="1.3 创建第一个数据库节点node1"></a>1.3 创建第一个数据库节点node1</h3><p>我们只需要向PXC镜像传入运行参数就能创建出PXC容器</p>
<p>注意，每个MySQL容器创建之后，因为要执行PXC的初始化和加入集群等工作，<strong>耐心等待1分钟左右</strong>再用客户端连接MySQL。</p>
<pre><code># 创建第1个MySQL节点
# MYSQL_ROOT_PASSWORD是数据库登录密码
# CLUSTER_NAME是集群名字
# XTRABACKUP_PASSWORD是集群内节点间同步密码
docker run -d -p 3307:3306 -e MYSQL_ROOT_PASSWORD=abc123456 -e CLUSTER_NAME=PXC -e XTRABACKUP_PASSWORD=abc123456 -v v1:/var/lib/mysql --privileged --name=node1 --net=net1 --ip 172.19.0.2 pxc
</code></pre><ul>
<li>按照视频教程的命令启动PXC容器时一直失败，报如下错误：mkdir: cannot create directory ‘’: No such file or directory。后来在<a href="https://blog.csdn.net/buildcourage/article/details/85054773" target="_blank" rel="noopener">博客</a>中找到了解决方法。<strong>命令里面除掉 “–-privileged”参数</strong>，去掉这个参数后节点启动正常。</li>
</ul>
<h3 id="1-4-创建剩余节点"><a href="#1-4-创建剩余节点" class="headerlink" title="1.4 创建剩余节点"></a>1.4 创建剩余节点</h3><p>创建集群其他节点命令和创建node1的命令有一些不同之处</p>
<ol>
<li>端口映射要修改一下，宿主机3307端口已经被node1占用了</li>
<li>多了一句命令“-e CLUSTER_JOIN=node1”，代表加入node1所属集群</li>
<li>映射的数据卷也不一样，这里从v2到v5</li>
<li>节点名字从node2到node5</li>
<li>ip地址也各不相同</li>
</ol>
<p><strong>必须第1个MySQL节点启动成功（大约等1-2分钟），用MySQL客户端能连接上之后，再去创建其他MySQL节点。</strong></p>
<pre><code># 创建第2个MySQL节点
docker run -d -p 3308:3306 -e MYSQL_ROOT_PASSWORD=abc123456 -e CLUSTER_NAME=PXC -e XTRABACKUP_PASSWORD=abc123456 -e CLUSTER_JOIN=node1 -v v2:/var/lib/mysql --privileged --name=node2 --net=net1 --ip 172.19.0.3 pxc
# 创建第3个MySQL节点
docker run -d -p 3309:3306 -e MYSQL_ROOT_PASSWORD=abc123456 -e CLUSTER_NAME=PXC -e XTRABACKUP_PASSWORD=abc123456 -e CLUSTER_JOIN=node1 -v v3:/var/lib/mysql --privileged --name=node3 --net=net1 --ip 172.19.0.4 pxc
# 创建第4个MySQL节点
docker run -d -p 3310:3306 -e MYSQL_ROOT_PASSWORD=abc123456 -e CLUSTER_NAME=PXC -e XTRABACKUP_PASSWORD=abc123456 -e CLUSTER_JOIN=node1 -v v4:/var/lib/mysql --privileged --name=node4 --net=net1 --ip 172.19.0.5 pxc
# 创建第5个MySQL节点
docker run -d -p 3311:3306 -e MYSQL_ROOT_PASSWORD=abc123456 -e CLUSTER_NAME=PXC -e XTRABACKUP_PASSWORD=abc123456 -e CLUSTER_JOIN=node1 -v v5:/var/lib/mysql --privileged --name=node5 --net=net1 --ip 172.19.0.6 pxc
</code></pre><p>最后效果：</p>
<div align="center"><br><img src="https://i.imgur.com/e8SDJtU.png"><br></div>

<p>此时我们使用workbench连接这5个数据库，分别是宿主机IP:3307-3311。<br>随后我们在node1上创建数据库class,在class里添加表student（包含id和name）。然后到其他节点中刷新后可以看到，他们也自动增加了数据库class和表student。<br>在node2中student里新建记录{1，jack}，{2,peter}。可以看到节点1上也新增了这些信息。</p>
<div align="center"><br><img src="https://i.imgur.com/KolJmXj.png" width="265" height="270"><br><img src="https://i.imgur.com/gguqbtl.png" width="280" height="270"><br></div>

<h2 id="2-负载均衡及双机热备的实现"><a href="#2-负载均衡及双机热备的实现" class="headerlink" title="2. 负载均衡及双机热备的实现"></a>2. 负载均衡及双机热备的实现</h2><p>使用Haproxy做负载均衡，请求被均匀分发给每个节点，单节点负载低，性能好。这里使用Haproxy来做负载均衡。</p>
<div align="center"><br><img src="https://i.imgur.com/Z06VxG5.png" width="490" height="295"><br></div>


<h3 id="2-1-下载镜像-amp-创建配置文件"><a href="#2-1-下载镜像-amp-创建配置文件" class="headerlink" title="2.1 下载镜像&amp;创建配置文件"></a>2.1 下载镜像&amp;创建配置文件</h3><pre><code># 下载镜像
docker pull haproxy
</code></pre><p>Haproxy容器是不带配置文件的，我们需要在宿主机上写好配置文件，然后通过文件映射，让haproxy容器读到配置文件。配置文件详情可以参考<a href="https://zhangge.net/5125.html" target="_blank" rel="noopener">这篇博客</a></p>
<pre><code># 新增haproxy配置文件（配置文件所在目录自己指定）
touch /home/soft/haproxy.cfg
</code></pre><p>配置文件haproxy.cfg：</p>
<pre><code>global
    # 工作目录
    chroot /usr/local/etc/haproxy
    # 日志文件，使用rsyslog服务中local5日志设备（/var/log/local5），等级info
    log 127.0.0.1 local5 info
    # 守护进程运行
    daemon

defaults
    log    global
    mode    http
    # 日志格式
    option    httplog
    # 日志中不记录负载均衡的心跳检测记录
    option    dontlognull
    # 连接超时（毫秒）
    timeout connect 5000
    # 客户端超时（毫秒）
    timeout client  50000
    # 服务器超时（毫秒）
    timeout server  50000

# 监控界面    
listen  admin_stats
    # 监控界面的访问的IP和端口
    bind  0.0.0.0:8888
    # 访问协议
    mode        http
    # URI相对地址
    stats uri   /dbs
    # 统计报告格式
    stats realm     Global\ statistics
    # 登陆帐户信息
    stats auth  admin:abc123456

# 数据库负载均衡（定义了一个配置，这个配置叫proxy-mysql）
listen  proxy-mysql
    # 访问的IP和端口，haproxy服务的端口是3306，任何IP都可以访问haproxy的3306端口
    bind  0.0.0.0:3306  
    # 网络协议
    mode  tcp
    # 负载均衡算法（轮询算法）
    # 轮询算法：roundrobin
    # 权重算法：static-rr
    # 最少连接算法：leastconn
    # 请求源IP算法：source 
    balance  roundrobin
    # 日志格式
    option  tcplog
    # 在MySQL中创建一个没有权限的haproxy用户（也可以起其他名字），密码为空。Haproxy使用这个账户对MySQL数据库心跳检测
    option  mysql-check user haproxy
    # 给每个被检测的数据库节点起名并注明它的IP和端口，分配权重（轮询的话权重就忽略了）和最大连接数
    server  MySQL_1 172.19.0.2:3306 check weight 1 maxconn 2000  
    server  MySQL_2 172.19.0.3:3306 check weight 1 maxconn 2000  
    server  MySQL_3 172.19.0.4:3306 check weight 1 maxconn 2000 
    server  MySQL_4 172.19.0.5:3306 check weight 1 maxconn 2000
    server  MySQL_5 172.19.0.6:3306 check weight 1 maxconn 2000
    # 使用keepalive检测死链
    option  tcpka
</code></pre><p>配置文件完成后，先在MySQL数据库里创建一个名叫haproxy的用户，没有初始密码。sql语句为：</p>
<pre><code>CREATE USER &apos;haproxy&apos;@&apos;%&apos; IDENTIFIED BY &apos;&apos;;
</code></pre><h3 id="2-2-创建Haproxy容器"><a href="#2-2-创建Haproxy容器" class="headerlink" title="2.2 创建Haproxy容器"></a>2.2 创建Haproxy容器</h3><p>创建一个haproxy容器</p>
<pre><code># haproxy负载均衡服务是运行在3306端口的，这里映射到宿主机的4002端口
# haproxy在配置文件中会定义一个后台监控UI的端口，在我们的配置文件中定义的是8888，所以也需要把这个端口映射出来
docker run -it -d -p 4001:8888 -p 4002:3306 -v /home/soft/haproxy:/usr/local/etc/haproxy --name h1 --privileged --net=net1 --ip 172.19.0.7 haproxy
# 进入h1容器
docker exec -it h1 bash
# 启动Haproxy，加载配置文件
haproxy -f /usr/local/etc/haproxy/haproxy.cfg
# 退出容器
exit
</code></pre><p>使用docker ps确认haproxy正常运行</p>
<div align="center"><br><img src="https://i.imgur.com/UfHoFmq.png"><br></div>

<p>随后我们登录宿主机IP:4001/dbs，账户名和密码已经在配置文件中写好了（这里是admin/abc123456），随后就可以看到5个mysql节点的监控状态。</p>
<div align="center"><br><img src="https://i.imgur.com/WVlBHf0.png"><br></div>

<p>现在使用workbench连接宿主机IP:4002，往里面添加class数据库里student表添加记录{3,ben}。这条记录就会被haproxy轮询到某一个mysql节点上，随后经过pxc的同步，所有mysql节点上都更新了此信息。</p>
<h3 id="2-3-Haproxy双机热备"><a href="#2-3-Haproxy双机热备" class="headerlink" title="2.3 Haproxy双机热备"></a>2.3 Haproxy双机热备</h3><p>单节点Haproxy不具备高可用，一旦宕机则导致数据库集群不可用，所以必须有冗余设计。这里实现Haproxy的双机热备。</p>
<div align="center"><br><img src="https://i.imgur.com/vzYqsQA.png" width="585" height="225"><br></div>

<p>linux系统可以给网卡创建虚拟IP，每个虚拟IP都对应一个应用程序。<br>我们运行两个haproxy容器，两个容器都安装keepalived，这个程序的作用是争抢网卡的虚拟IP，谁先抢到谁就用。没有抢到的那个就属于备服务器，处于等待状态。主服务器和备服务器之间一直在做心跳检测，一旦备服务器发现主服务器宕机，它就会去争抢虚拟IP，开始工作。应用程序向这个虚拟IP发送请求，我们不必在乎是哪个haproxy节点工作。</p>
<div align="center"><br><img src="https://i.imgur.com/jRzrekT.png" width="431" height="225"><br></div>

<p>下图是我们的Haproxy双机热备方案（IP稍有改动）。</p>
<div align="center"><br><img src="https://i.imgur.com/FjapNnX.png" width="940" height="300"><br></div>

<h3 id="2-4-安装-amp-启动keepalived"><a href="#2-4-安装-amp-启动keepalived" class="headerlink" title="2.4 安装&amp;启动keepalived"></a>2.4 安装&amp;启动keepalived</h3><p>keepalived必须安装在Haproxy所在的容器之内。因为haproxy镜像是在Ubuntu基础上创建出来的，所以这里用的是apt-get。</p>
<pre><code># 进入h1容器
docker exec -it h1 bash
# 更新软件包
apt-get update
# 安装Keepalived
apt-get install keepalived
# 安装VIM
apt-get install vim
# 安装Keepalived
apt-get install keepalived
# 编辑Keepalived配置文件
vim /etc/keepalived/keepalived.conf
</code></pre><p>增加keepalived的配置文件，路径为/etc/keepalived/keepalived.conf</p>
<p>配置文件keepalived.conf内容如下：</p>
<pre><code>vrrp_instance  VI_1 {
    state  MASTER
    interface  eth0
    virtual_router_id  51
    priority  100
    advert_int  1
    authentication {
        auth_type  PASS
        auth_pass  123456
    }
    virtual_ipaddress {
        172.19.0.201
    }
}
</code></pre><ul>
<li>state:如果是MASTER，启动后会去争抢虚拟IP，如果没有抢到，自动降级为BACKUOP，如果是BACKUP，就不会去争抢虚拟IP。</li>
<li>interface：网卡设备。记录了虚拟IP存在哪一个网卡上面。eth0是docker虚拟机的网卡，宿主机是可以看到eth0的，但是出了宿主机，在局域网上其他主机就看不到了。要在局域网上使用，就必须在宿主机上安装keepalived，将eth0上的虚拟IP映射成局域网上的某个IP。</li>
<li>virtual_router_id：虚拟路由标识，MASTER和BACKUP的虚拟路由标识必须一致。介于0~255，就是给keepalived起了一个名字。</li>
<li>priority：抢占虚拟IP的权重。</li>
<li>advert_int：心跳检测的时间，以秒为单位，主备之间必须一致。</li>
<li>authentication：主从服务器的验证方式。主备必须使用相同的密码才能正常通信。</li>
<li>virtual_ipaddress：虚拟IP地址，可以设置多个，每行一个。这个虚拟IP只能在docker虚拟机内部看得见。</li>
</ul>
<p>接着进入haproxy节点，开启keepalived</p>
<pre><code># 在docker虚拟机里启动Keepalived
service keepalived start
# 随后退出容器
exit
# 在宿主机里可以去ping这个虚拟IP，ping通就表示keepalived启动成功
ping 172.19.0.201
</code></pre><p>如图</p>
<div align="center"><br><img src="https://i.imgur.com/Mbjg9nv.png"><br></div>

<p>说明keepalived已经在h1里成功运行了。接着依样画葫芦完成对h2的操作。</p>
<pre><code># 创建第2个Haproxy负载均衡服务器
docker run -it -d -p 4003:8888 -p 4004:3306 -v /home/soft/haproxy:/usr/local/etc/haproxy --name h2 --privileged --net=net1 --ip 172.19.0.8 haproxy
# 进入h2容器，启动Haproxy
docker exec -it h2 bash
haproxy -f /usr/local/etc/haproxy/haproxy.cfg
# 更新软件包
apt-get update
# 安装VIM
apt-get install vim
# 安装Keepalived
apt-get install keepalived
# 编辑Keepalived配置文件（和h1相同）
vim /etc/keepalived/keepalived.conf
# 启动Keepalived
service keepalived start
# 退出h2
exit
</code></pre><p>现在我们已经有两个haproxy节点，抢占了172.19.0.201这个IP的haproxy节点成为MASTER，开始工作，另一个成为备份节点。但是Docker虚拟机内的虚拟IP不能为外网所访问。所以需要在宿主机上安装keepalived将172.19.0.201映射成外网可以访问的IP。</p>
<pre><code># 宿主机执行安装Keepalived
yum -y install keepalived
# 修改Keepalived配置文件
vim /etc/keepalived/keepalived.conf
# 启用keepalived
service keepalived start
</code></pre><p>keepalived.conf文件配置内容如下：</p>
<pre><code>vrrp_instance VI_1 {
    state MASTER
    # 这里是宿主机的网卡，可以通过ip a查看当前自己电脑上用的网卡名是哪个
    interface ens33
    virtual_router_id 51
    priority 100
    advert_int 1
    authentication {
        auth_type PASS
        auth_pass 1111
    }
    # 这里是指定的一个宿主机上的虚拟ip，一定要和宿主机网卡在同一个网段
    # 例如宿主机网卡ip是192.168.99.149，指定虚拟ip是150
    virtual_ipaddress {
           192.168.99.150
    }
}

# 接受监听数据来源的端口，网页入口使用
virtual_server 192.168.99.150 8888 {
    delay_loop 3
    lb_algo rr
    lb_kind NAT
    persistence_timeout 50
    protocol TCP
    # 把接受到的数据转发给docker服务的网段及端口，由于是发给docker服务，所以和docker服务数据要一致
    real_server 172.19.0.201 8888 {
        weight 1
    }
}

# 接受数据库数据端口，宿主机数据库端口是3306，所以这里也要和宿主机数据接受端口一致
virtual_server 192.168.99.150 3306 {
    delay_loop 3
    lb_algo rr
    lb_kind NAT
    persistence_timeout 50
    protocol TCP
    # 同理转发数据库给服务的端口和ip要求和docker服务中的数据一致
    real_server 172.19.0.201 3306 {
        weight 1
    }
}
</code></pre><p>通过ip a查看网卡中是否出现定义的192.168.99.150 IP地址，如果没有出现可能是因为配置文件不正确。<br>通过ping 192.168.99.150，发现能够ping通，说明没问题<br>通过浏览器输入</p>
<pre><code>http://192.168.99.150:8888/dbs
</code></pre><p>即可看到Haproxy监控画面</p>
<div align="center"><br><img src="https://i.imgur.com/WVlBHf0.png"><br></div>

<h2 id="3-XtraBackup热备份-amp-冷还原数据"><a href="#3-XtraBackup热备份-amp-冷还原数据" class="headerlink" title="3. XtraBackup热备份&amp;冷还原数据"></a>3. XtraBackup热备份&amp;冷还原数据</h2><p>在完成了上面的工作之后，我们已经拥有了负载均衡双机热备+MySQL集群。现在实现如何进行数据备份和恢复。</p>
<p><strong>冷备份</strong></p>
<ul>
<li>冷备份是关闭数据库时候的备份方式，通常做法是拷贝数据文件</li>
<li>冷备份是最简单最安全的一种备份方式</li>
<li>大型网站无法做到关闭业务备份数据，所以冷备份不是最佳选择</li>
</ul>
<p><strong>热备份</strong></p>
<ul>
<li>热备份是在系统运行的状态下备份数据，也是难度最大的备份</li>
<li>MySQL常见的热备份有LVM和XtraBackup两种方案</li>
<li>因为LVM在热备份时要锁表，只能读不能写，因此建议使用XtraBackup</li>
</ul>
<p>XtraBackup是Percona公司推出的一款基于InnoDB的在线热备工具，开源免费，占用磁盘空间小，能够快速地备份与恢复mysql数据库。</p>
<ul>
<li>XtraBackup备份过程不锁表，快速可靠</li>
<li>XtraBackup备份过程不会打断正在执行的事务</li>
<li>XtraBackup能够基于压缩等功能节约磁盘空间和流量</li>
</ul>
<h3 id="3-1-XtraBackup热备份数据"><a href="#3-1-XtraBackup热备份数据" class="headerlink" title="3.1 XtraBackup热备份数据"></a>3.1 XtraBackup热备份数据</h3><p>XtraBackup可以进行全量备份和增量备份。这次我们使用全量备份。XtraBackup这个工具是运行在mysql容器里面的，备份的数据存在容器里肯定不好。我们在宿主机上创建备份映射，以后再有mysql节点想要根据备份恢复数据时，可以根据映射宿主机上的备份来完成。</p>
<pre><code># 创建备份数据卷backup
docker volume create backup
# 挂靠数据卷需要重新创建mysql节点。之前节点的数据库内容已经存在v1了，所以不需要担心数据丢失的问题。
# 停止node1
docker stop node1
# 删除node1
docker rm node1
# 重新创建node1，这次增加了&quot;backup:/data&quot;，同时&quot;-e CLUSTER_JOIN=node2&quot;即表示加入原先网络
docker run -d -p 3307:3306 -e MYSQL_ROOT_PASSWORD=abc123456 -e CLUSTER_NAME=PXC -e XTRABACKUP_PASSWORD=abc123456 -e CLUSTER_JOIN=node2 -v v1:/var/lib/mysql -v backup:/data --privileged --name=node1 --net=net1 --ip 172.19.0.2 pxc
# 进入node1
docker exec -it node1 bash
# 更新软件包
apt-get update
# 安装热备工具
apt-get install percona-xtrabackup-24
#全量热备
innobackupex --user=root --password=abc123456 /data/backup/full
# 退出容器
exit
</code></pre><h3 id="3-2-数据冷还原"><a href="#3-2-数据冷还原" class="headerlink" title="3.2 数据冷还原"></a>3.2 数据冷还原</h3><p>假如出现了数据库还原的需求（例如所有mysql节点都丢失了数据），那么我们热备份的数据就派上了用场。数据库只有冷还原。在PXC集群中执行冷还原的步骤为，解散集群，删除各个MySQL节点，创建一个新节点冷还原数据，随后创建其余节点同步数据。还原数据前要将未提交的事务回滚，还原数据之后重启MySQL。</p>
<p>如果找不到之前热备份的数据的路径，使用下面命令来查看：</p>
<pre><code>docker inspect backup
</code></pre><p>创建node1并完成数据冷还原</p>
<pre><code># 停止mysql节点
docker stop node1 node2 node3 node4 node5
# 删除mysql节点
docker rm node1 node2 node3 node4 node5
# 清空数据卷
docker volume rm node1 node2 node3 node4 node5
# 创建node1
docker run -d -p 3307:3306 -e MYSQL_ROOT_PASSWORD=abc123456 -e CLUSTER_NAME=PXC -e XTRABACKUP_PASSWORD=abc123456 -v v1:/var/lib/mysql -v backup:/data --privileged --name=node1 --net=net1 --ip 172.19.0.2 pxc
# 进入node1,在node1内实现冷还原
docker exec -it node1 bash
# 删除数据
rm -rf /var/lib/mysql/*
# 清空未提交事务
# &quot;/data/backup/full/2018-04-15_05-09-07/&quot;是我们之前热备份的数据
innobackupex --user=root --password=abc123456 --apply-back /data/backup/full/2018-04-15_05-09-07/
#还原数据
innobackupex --user=root --password=abc123456 --copy-back  /data/backup/full/2018-04-15_05-09-07/
# 退出容器
exit
# 重启node1
docker stop node1
docker start node1
</code></pre><p>重新创建其余4个节点，加入PXC集群自动同步即可</p>
<p>相关链接：</p>
<p><a href="https://blog.csdn.net/tianshuhao521/article/details/84782309" target="_blank" rel="noopener">https://blog.csdn.net/tianshuhao521/article/details/84782309</a></p>
<p><a href="https://blog.csdn.net/buildcourage/article/details/85054773" target="_blank" rel="noopener">https://blog.csdn.net/buildcourage/article/details/85054773</a></p>
<p><a href="https://zhaobugs.com/2018/06/06/Docker%E6%90%AD%E5%BB%BAPXC%E9%9B%86%E7%BE%A4/" target="_blank" rel="noopener">https://zhaobugs.com/2018/06/06/Docker%E6%90%AD%E5%BB%BAPXC%E9%9B%86%E7%BE%A4/</a></p>
<p><a href="https://blog.csdn.net/qq_21108311/article/details/82973763" target="_blank" rel="noopener">https://blog.csdn.net/qq_21108311/article/details/82973763</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/01/15/Docker-Front-End-Sep-02/" data-id="cjsu8vdc30007jwcz5wv2ofor" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Haproxy/">Haproxy</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/MySQL/">MySQL</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/XtraBackup/">XtraBackup</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/docker/">docker</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-Docker-Front-End-Sep-01" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/01/14/Docker-Front-End-Sep-01/" class="article-date">
  <time datetime="2019-01-14T12:20:08.000Z" itemprop="datePublished">2019-01-14</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/01/14/Docker-Front-End-Sep-01/">Docker环境下的前后端分离项目部署与运维笔记01</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>内容来源：<a href="https://coding.imooc.com/class/219.html" target="_blank" rel="noopener">Docker环境下的前后端分离项目部署与运维</a></p>
<p>要做什么：使用Docker部署前后端分离项目<a href="https://www.renren.io/" target="_blank" rel="noopener">renren-fast</a>。<br>利用多节点集群实现高性能、高负载、高可用。<br>源码都已经公开，本次的重点在于部署运维。</p>
<p><img src="https://i.imgur.com/shGl8Al.png" alt=""></p>
<h2 id="开源项目renren-fast"><a href="#开源项目renren-fast" class="headerlink" title="开源项目renren-fast"></a>开源项目renren-fast</h2><p>renren-fast 是一个轻量级的 Spring Boot 快速开发平台，能快速开发项目并交付。项目是前后端分离的，需要先部署好后端，再部署前端页面。<a href="https://www.renren.io/guide/" target="_blank" rel="noopener">官方部署教程</a></p>
<h3 id="后台项目renren-fast"><a href="#后台项目renren-fast" class="headerlink" title="后台项目renren-fast"></a>后台项目renren-fast</h3><p>框架：SSM（Spring+SpringMVC+MyBatis）；权限管理：Shiro；高速缓存：Redis；后台API调试：Swagger；保存授权认证信息：JWT<br>（在微服务架构下，用户在访问服务A之后再去访问服务B，肯定是不能再去重复认证了。这里就牵扯到单点登录的问题了，JWT将认证信息保存在浏览器上面。）</p>
<p><img src="https://i.imgur.com/IodtMiX.png" alt=""></p>
<p>本机部署renren-fast需要注意：renren_fast是springboot构建的，后者用到的是Maven技术。所以本地需要提前安装好jdk，配置环境变量。同时也要根据jdk版本，下载好<a href="http://maven.apache.org/download.cgi" target="_blank" rel="noopener">Maven</a>（Maven是一套软件工程整理和整合工具，不需要安装，解压即可用），配置好环境变量，把Maven的镜像设置为国内阿里云镜像。Maven和renren_fast项目中的pom文件组合即可构建出对应工程。</p>
<p><img src="https://i.imgur.com/9taDwLk.png" alt=""></p>
<p>其余的安装官方教程就可以了。</p>
<p>在启动renren-fast之后，为了检验后台项目是否正常运行。打开<a href="http://localhost:8080/renren-fast/swagger/index.html" target="_blank" rel="noopener">Swagger</a>。可以看到有很多后台API可供调用。我们来测试一下用户登录。</p>
<p><img src="https://i.imgur.com/rAwBU58.png" alt=""></p>
<p>在获取验证码内我们输入UUID=“1234”，点击“试一下”，得到返回的验证码。</p>
<p><img src="https://i.imgur.com/K1Y3rH9.png" alt=""></p>
<p>随后在用户登录部分，在body内填入对应用户名，密码，验证码(登录的账号密码：admin/admin)和UUID。点击“试一下”即可看到我们得到了正确的response。</p>
<p><img src="https://i.imgur.com/zDmGmzr.png" alt=""></p>
<p><img src="https://i.imgur.com/NbT5use.png" alt=""></p>
<p>到这里，就说明后台项目在本机正常运行啦！</p>
<h3 id="前端项目renren-fast-vue"><a href="#前端项目renren-fast-vue" class="headerlink" title="前端项目renren-fast-vue"></a>前端项目renren-fast-vue</h3><p>renren-fast-vue基于vue、element-ui构建开发，实现renren-fast后台管理前端功能。</p>
<p>这部分在本机的安装部署就很简单了，前提是安装好nodejs。</p>
<pre><code># 克隆项目
git clone https://github.com/daxiongYang/renren-fast-vue.git
# 进入项目目录
cd renren-fast-vue
# 安装依赖(可能要等几分钟)
npm install
# 启动服务
npm run dev
</code></pre><p>在启动服务之后可以打开本地8001端口（在后台项目运行的情况下），使用账号密码：admin/admin登录，体验renren-fast后台管理。</p>
<p><img src="https://i.imgur.com/hQVMDiE.png" alt=""></p>
<p><img src="https://i.imgur.com/8jG6HrX.png" alt=""></p>
<p>至此，我们就已经完成了renren-fast在本机上的部署啦！</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/01/14/Docker-Front-End-Sep-01/" data-id="cjsu8vdbb0000jwcznn5kkiq2" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/docker/">docker</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/java/">java</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/windows/">windows</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-hello" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/01/13/hello/" class="article-date">
  <time datetime="2019-01-13T13:28:25.000Z" itemprop="datePublished">2019-01-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/01/13/hello/">你好</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>欢迎来到 <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>！这是你的第一篇博文。</p>
<h2 id="快速开始"><a href="#快速开始" class="headerlink" title="快速开始"></a>快速开始</h2><h3 id="创建一篇新博文"><a href="#创建一篇新博文" class="headerlink" title="创建一篇新博文"></a>创建一篇新博文</h3><p>$ hexo new post “My New Post”</p>
<p>更多信息……</p>
<h2 id="结语"><a href="#结语" class="headerlink" title="结语"></a>结语</h2><p>谢谢你使用 Hexo。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/01/13/hello/" data-id="cjsu8vdc7000ajwczk8bv901r" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/demo/">demo</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hello/">hello</a></li></ul>

    </footer>
  </div>
  
</article>


  
    <article id="post-hello-world" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/01/13/hello-world/" class="article-date">
  <time datetime="2019-01-13T13:22:37.128Z" itemprop="datePublished">2019-01-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/01/13/hello-world/">Hello World</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/01/13/hello-world/" data-id="cjsu8vdcc000ejwcz74m4ne6x" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tags</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/Haproxy/">Haproxy</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/MySQL/">MySQL</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/XtraBackup/">XtraBackup</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/centos7/">centos7</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/demo/">demo</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/docker/">docker</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/firewall/">firewall</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/golang/">golang</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/hello/">hello</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/iris/">iris</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/java/">java</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/redis/">redis</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/renren-fast/">renren-fast</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/windows/">windows</a></li><li class="tag-list-item"><a class="tag-list-link" href="/tags/xorm/">xorm</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/Haproxy/" style="font-size: 10px;">Haproxy</a> <a href="/tags/MySQL/" style="font-size: 10px;">MySQL</a> <a href="/tags/XtraBackup/" style="font-size: 10px;">XtraBackup</a> <a href="/tags/centos7/" style="font-size: 10px;">centos7</a> <a href="/tags/demo/" style="font-size: 10px;">demo</a> <a href="/tags/docker/" style="font-size: 20px;">docker</a> <a href="/tags/firewall/" style="font-size: 10px;">firewall</a> <a href="/tags/golang/" style="font-size: 10px;">golang</a> <a href="/tags/hello/" style="font-size: 10px;">hello</a> <a href="/tags/iris/" style="font-size: 10px;">iris</a> <a href="/tags/java/" style="font-size: 10px;">java</a> <a href="/tags/redis/" style="font-size: 10px;">redis</a> <a href="/tags/renren-fast/" style="font-size: 10px;">renren-fast</a> <a href="/tags/windows/" style="font-size: 10px;">windows</a> <a href="/tags/xorm/" style="font-size: 10px;">xorm</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/02/">二月 2019</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">一月 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/02/27/Docker-Front-End-Sep-04/">Docker环境下的前后端分离项目部署与运维04:后端项目部署</a>
          </li>
        
          <li>
            <a href="/2019/01/30/footballStarBase-01/">iris+xorm Go语言开发球星库(一)</a>
          </li>
        
          <li>
            <a href="/2019/01/29/Docker-Front-End-Sep-03/">Redis集群搭建</a>
          </li>
        
          <li>
            <a href="/2019/01/16/firewall-centos7/">Centos7上防火墙常用设置</a>
          </li>
        
          <li>
            <a href="/2019/01/15/Docker-Front-End-Sep-02/">Docker环境下的前后端分离项目部署与运维02:高可用MySQL集群搭建</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 Chen Yongming<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>